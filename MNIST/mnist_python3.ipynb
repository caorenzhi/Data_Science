{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from math import exp, log\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import gzip\n",
    "from matplotlib import pyplot\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data_file_name = {\n",
    "    'train_image':'train-images-idx3-ubyte.gz',\n",
    "    'train_label':'train-labels-idx1-ubyte.gz',\n",
    "    'test_image':'t10k-images-idx3-ubyte.gz',\n",
    "    'test_label':'t10k-labels-idx1-ubyte.gz'\n",
    "}\n",
    "\n",
    "dir_data_file = './data'\n",
    "\n",
    "train_num = 60000\n",
    "test_num = 10000\n",
    "image_dimension = (1, 28, 28)\n",
    "image_size = 784\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LoadLabel(file_name):\n",
    "    # file_name의 Binary 파일을 읽어서 numpy.ndarray 를 Return 한다.\n",
    "    file_path = dir_data_file + \"/\" + file_name\n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    rtval = data\n",
    "    print(file_name + \" file loaded\")\n",
    "    return rtval\n",
    "\n",
    "def LoadImage(file_name):\n",
    "    # file_name의 Binary 파일을 읽어서 numpy.ndarray 를 Return 한다.\n",
    "    file_path = dir_data_file + \"/\" + file_name   \n",
    "    with gzip.open(file_path, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    rtval = data.reshape(-1, image_size)\n",
    "    print(file_name + \" file loaded\")\n",
    "    return rtval\n",
    "\n",
    "def DictoNumpy():\n",
    "    ## Dictionary data-type으로 \n",
    "    dic_data = {}\n",
    "    print(type(dic_data))\n",
    "    dic_data['train_image'] =  LoadImage(data_file_name['train_image'])\n",
    "    dic_data['train_label'] = LoadLabel(data_file_name['train_label'])    \n",
    "    dic_data['test_image'] = LoadImage(data_file_name['test_image'])\n",
    "    dic_data['test_label'] = LoadLabel(data_file_name['test_label'])\n",
    "    \n",
    "    return dic_data\n",
    "\n",
    "def ImageDisplay(list_data):\n",
    "    ## List형의 Pixcel 정보를 받아서 이미지로 보여준다.\n",
    "    fig = pyplot.figure()\n",
    "    axis = fig.add_subplot(1,1,1)\n",
    "    plot_img = axis.imshow(list_data, cmap=mpl.cm.Greys)\n",
    "    plot_img.set_interpolation('none')\n",
    "#    ax.xaxis.set_ticks_position('top')\n",
    "#    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.show()\n",
    "\n",
    "def ascii_show(image):\n",
    "    for y in image:\n",
    "        row = \"\"\n",
    "        for x  in y:\n",
    "            row += '{0: <4}'.format(x)\n",
    "        print (row)\n",
    "        \n",
    "        \n",
    "def MakeNetwork(sizes):\n",
    "    num_layers = len(sizes)\n",
    "    input_layer, hidden_layer, output_layer = sizes \n",
    "    \n",
    "    biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "    weights = [np.random.randn(y, x) \n",
    "                for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "    \n",
    "    return num_layers, biases, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "train-images-idx3-ubyte.gz file loaded\n",
      "train-labels-idx1-ubyte.gz file loaded\n",
      "t10k-images-idx3-ubyte.gz file loaded\n",
      "t10k-labels-idx1-ubyte.gz file loaded\n",
      "<class 'numpy.ndarray'>\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113ac9dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## MNIST Model 설계 \n",
    "## X = [ 784 x 1 ] , W1 = [ 30 x 784 ], B1 = [ 30 x 1 ]\n",
    "## A1 = [ 30 x 1 ] , W2 = [ 10 x 30 ], B2 = [ 10 x 1 ]\n",
    "## A2 = [ 10 x 1 ]\n",
    "\n",
    "\n",
    "sizes = [784, 30, 10]\n",
    "num_layers, biases, weights = MakeNetwork(sizes)\n",
    "\n",
    "dic_data = DictoNumpy()\n",
    "\n",
    "print (type(dic_data['train_image'][0]))\n",
    "print (dic_data['train_label'][0])\n",
    "ImageDisplay (dic_data['train_image'][0].reshape(28,28))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Sigmoid(x):\n",
    "    return 1.0/(1.0+np.exp(-x))\n",
    "\n",
    "def SigmoidPrime(x):\n",
    "    return Sigmoid(x)*(1-Sigmoid(x))\n",
    "\n",
    "def SoftMax(x):\n",
    "    exp = np.exp(x-np.max(x))\n",
    "    return exp / np.sum(exp)\n",
    "\n",
    "def OneHotLabel(x):\n",
    "    onehot = np.zeros((x.size, 10))\n",
    "    for i, row in enumerate(onehot):\n",
    "        row[x[i]] = 1\n",
    "    return onehot \n",
    "\n",
    "def ForwardPropagation(x, w, b):\n",
    "    a = np.dot(w, x) + b\n",
    "    a = a/255\n",
    "    return a # Sigmoid(a)\n",
    "\n",
    "def MeanSqrError(y, t):\n",
    "    return 0.5*np.sum((y-t)**2)\n",
    "\n",
    "def CrossEntropy ( y, t ):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y+delta))\n",
    "\n",
    "def PredictOutput(x, weight, biases):\n",
    "    y1 = ForwardPropagation(x,weights[0],biases[0].reshape(30,))\n",
    "    a1 = Sigmoid(y1)\n",
    "    y2 = ForwardPropagation(a1,weights[1],biases[1].reshape(10,))\n",
    "    return y2\n",
    "\n",
    "def BackProp (x, layer1, a1, a2, d, weights):\n",
    "    # DIM (10,1)\n",
    "    delta_b2 = (a2-d).reshape(10,1)   \n",
    "    # DIM (10, 30)\n",
    "    delta_w2 = np.dot(delta_b2,a1.reshape(1,30))  \n",
    "    # DIM (30, 1 )\n",
    "    delta_b1 = np.dot(weights[1].reshape(30,10),delta_b2)*SigmoidPrime(layer1.reshape(30,1))\n",
    "    # DIM (30, 784)\n",
    "    delta_w1 = np.dot(delta_b1, x.reshape(1,784))\n",
    "    \n",
    "    return delta_w1, delta_b1, delta_w2, delta_b2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sizes = [784, 30, 10]\n",
    "num_layers, biases, weights = MakeNetwork(sizes)\n",
    "save_init_random_b = biases\n",
    "save_init_random_w = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate :  0.1\n",
      "-----------------------------------------------\n",
      "Epoch : 1 1000 train-err 0.324 test-err 0.2565\n",
      "Epoch : 2 2000 train-err 0.549 test-err 0.4354\n",
      "Epoch : 3 3000 train-err 0.708 test-err 0.6123\n",
      "Epoch : 4 4000 train-err 0.795 test-err 0.6881\n",
      "Epoch : 5 5000 train-err 0.827 test-err 0.7443\n",
      "Epoch : 6 6000 train-err 0.844 test-err 0.7756\n",
      "Epoch : 7 7000 train-err 0.88 test-err 0.807\n",
      "Epoch : 8 8000 train-err 0.88 test-err 0.8243\n",
      "Epoch : 9 9000 train-err 0.837 test-err 0.8149\n",
      "Epoch : 10 10000 train-err 0.906 test-err 0.8184\n",
      "Epoch : 11 11000 train-err 0.906 test-err 0.8245\n",
      "Epoch : 12 12000 train-err 0.886 test-err 0.8258\n",
      "Epoch : 13 13000 train-err 0.888 test-err 0.832\n",
      "Epoch : 14 14000 train-err 0.887 test-err 0.8265\n",
      "Epoch : 15 15000 train-err 0.86 test-err 0.8489\n",
      "Epoch : 16 16000 train-err 0.89 test-err 0.8378\n",
      "Epoch : 17 17000 train-err 0.872 test-err 0.8553\n",
      "Epoch : 18 18000 train-err 0.878 test-err 0.8398\n",
      "Epoch : 19 19000 train-err 0.931 test-err 0.8402\n",
      "Epoch : 20 20000 train-err 0.901 test-err 0.8354\n",
      "Epoch : 21 21000 train-err 0.878 test-err 0.8364\n",
      "Epoch : 22 22000 train-err 0.917 test-err 0.8481\n",
      "Epoch : 23 23000 train-err 0.891 test-err 0.8485\n",
      "Epoch : 24 24000 train-err 0.897 test-err 0.8504\n",
      "Epoch : 25 25000 train-err 0.885 test-err 0.8548\n",
      "Epoch : 26 26000 train-err 0.912 test-err 0.853\n",
      "Epoch : 27 27000 train-err 0.912 test-err 0.8545\n",
      "Epoch : 28 28000 train-err 0.906 test-err 0.8475\n",
      "Epoch : 29 29000 train-err 0.905 test-err 0.8516\n",
      "Epoch : 30 30000 train-err 0.891 test-err 0.8481\n",
      "Epoch : 31 31000 train-err 0.895 test-err 0.8439\n",
      "Epoch : 32 32000 train-err 0.874 test-err 0.8538\n",
      "Epoch : 33 33000 train-err 0.889 test-err 0.853\n",
      "Epoch : 34 34000 train-err 0.921 test-err 0.8547\n",
      "Epoch : 35 35000 train-err 0.908 test-err 0.8562\n",
      "Epoch : 36 36000 train-err 0.917 test-err 0.8526\n",
      "Epoch : 37 37000 train-err 0.923 test-err 0.8536\n",
      "Epoch : 38 38000 train-err 0.877 test-err 0.848\n",
      "Epoch : 39 39000 train-err 0.897 test-err 0.8643\n",
      "Epoch : 40 40000 train-err 0.896 test-err 0.8533\n",
      "Epoch : 41 41000 train-err 0.923 test-err 0.8575\n",
      "Epoch : 42 42000 train-err 0.91 test-err 0.8529\n",
      "Epoch : 43 43000 train-err 0.888 test-err 0.8635\n",
      "Epoch : 44 44000 train-err 0.923 test-err 0.8534\n",
      "Epoch : 45 45000 train-err 0.9 test-err 0.856\n",
      "Epoch : 46 46000 train-err 0.884 test-err 0.8642\n",
      "Epoch : 47 47000 train-err 0.905 test-err 0.858\n",
      "Epoch : 48 48000 train-err 0.886 test-err 0.8653\n",
      "Epoch : 49 49000 train-err 0.918 test-err 0.8625\n",
      "Epoch : 50 50000 train-err 0.875 test-err 0.8614\n",
      "Epoch : 51 51000 train-err 0.893 test-err 0.8589\n",
      "Epoch : 52 52000 train-err 0.919 test-err 0.8575\n",
      "Epoch : 53 53000 train-err 0.889 test-err 0.8575\n",
      "Epoch : 54 54000 train-err 0.909 test-err 0.8576\n",
      "Epoch : 55 55000 train-err 0.901 test-err 0.8643\n",
      "Epoch : 56 56000 train-err 0.92 test-err 0.8623\n",
      "Epoch : 57 57000 train-err 0.919 test-err 0.8588\n",
      "Epoch : 58 58000 train-err 0.91 test-err 0.855\n",
      "Epoch : 59 59000 train-err 0.956 test-err 0.8597\n",
      "Epoch : 60 60000 train-err 0.938 test-err 0.8573\n"
     ]
    }
   ],
   "source": [
    "## 학습 및 테스트 \n",
    "\n",
    "## Batch 처리\n",
    "batch_size = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "num_layers, biases, weights = MakeNetwork(sizes)\n",
    "input_data = dic_data['train_image']\n",
    "one_hot_output = OneHotLabel(dic_data['train_label'])\n",
    "\n",
    "test_data = dic_data['test_image']\n",
    "one_hot_output_test = OneHotLabel(dic_data['test_label'])\n",
    "\n",
    "layer1 = 0\n",
    "layer2 = 0\n",
    "a1 = 0\n",
    "a2 = 0\n",
    "\n",
    "train_err_list = []\n",
    "test_err_list = []\n",
    "\n",
    "print ('learning rate : ', learning_rate, )\n",
    "print ('-----------------------------------------------')\n",
    "\n",
    "for k in range(int(train_num/batch_size)): # sample selection\n",
    "\n",
    "    epoch_error = []\n",
    "    \n",
    "    for j in range(50): # learning repeat\n",
    "\n",
    "        dl_w1 = []\n",
    "        dl_b1 = []\n",
    "        dl_w2 = []\n",
    "        dl_b2 = []\n",
    "        \n",
    "        prediction_error_batch = []\n",
    "        \n",
    "        prediction_error = 0\n",
    "        \n",
    "\n",
    "        for i in range(batch_size):\n",
    "            idx = i+k*batch_size\n",
    "            layer1 = ForwardPropagation(input_data[idx],weights[0],biases[0].reshape(30,))\n",
    "            a1 = Sigmoid(layer1)\n",
    "            layer2 = ForwardPropagation(a1,weights[1],biases[1].reshape(10,))\n",
    "            a2 = layer2\n",
    "\n",
    "            d = np.array(one_hot_output[idx])\n",
    "            error = MeanSqrError(np.array(a2), d)\n",
    "\n",
    "\n",
    "            d_w1, d_b1, d_w2, d_b2 = BackProp(input_data[idx], layer1, a1, a2, np.array(one_hot_output[idx]), weights)\n",
    "\n",
    "            dl_w1.append(d_w1)\n",
    "            dl_b1.append(d_b1)\n",
    "            dl_w2.append(d_w2)\n",
    "            dl_b2.append(d_b2)\n",
    "            \n",
    "            if np.argmax(a2) == np.argmax(d):\n",
    "                prediction_error = prediction_error+1\n",
    "\n",
    "            prediction_error_batch.append(error)\n",
    "            \n",
    "        weights[0] = weights[0]-learning_rate*(sum(dl_w1)/batch_size)\n",
    "        biases[0] = biases[0]-learning_rate*(sum(dl_b1)/batch_size)\n",
    "        weights[1] = weights[1]-learning_rate*(sum(dl_w2)/batch_size)\n",
    "        biases[1] = biases[1]-learning_rate*(sum(dl_b2)/batch_size)\n",
    "    \n",
    "    test_error = 0\n",
    "    \n",
    "    for j in range(test_num):\n",
    "        idx = j\n",
    "        a2 = PredictOutput(test_data[idx],weights,biases )\n",
    "        d = np.array(one_hot_output_test[idx])\n",
    "        \n",
    "        if np.argmax(a2) == np.argmax(d):\n",
    "            test_error = test_error+1\n",
    "    \n",
    "    print ('Epoch :', k+1, (k+1)*batch_size, \"train-err\", prediction_error/batch_size, \"test-err\", test_error/test_num)\n",
    "    train_err_list.append(prediction_error/batch_size)\n",
    "    test_err_list.append(test_error/test_num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.88055822]\n",
      " [ 0.30497074]\n",
      " [-0.17961919]\n",
      " [-1.33175608]\n",
      " [-1.31084186]\n",
      " [-1.23496436]\n",
      " [ 0.51034618]\n",
      " [-0.96724618]\n",
      " [-0.20493018]\n",
      " [-0.02348805]]\n",
      "[[ 3.04380307]\n",
      " [ 7.60867869]\n",
      " [ 3.14219975]\n",
      " [ 2.96981264]\n",
      " [ 2.05106307]\n",
      " [ 1.15310446]\n",
      " [ 0.78291246]\n",
      " [ 5.12515177]\n",
      " [ 1.15337218]\n",
      " [ 1.6915618 ]]\n"
     ]
    }
   ],
   "source": [
    "print (save_init_random_b[1])\n",
    "print (biases[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.88055822]\n",
      " [ 0.30497074]\n",
      " [-0.17961919]\n",
      " [-1.33175608]\n",
      " [-1.31084186]\n",
      " [-1.23496436]\n",
      " [ 0.51034618]\n",
      " [-0.96724618]\n",
      " [-0.20493018]\n",
      " [-0.02348805]]\n"
     ]
    }
   ],
   "source": [
    "print (save_init_random_b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
